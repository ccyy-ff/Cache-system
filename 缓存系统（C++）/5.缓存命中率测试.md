# 5.缓存命中率测试

# 缓存测试结果展示
> <font style="color:rgb(31, 35, 40);">该测试代码只是尽可能地模拟真实的访问场景，但是跟真实的场景仍存在一定差距，测试结果仅供参考。</font>
>

![1744942097160-3b3ace89-9297-4f90-8dfd-ee94e32bcf8c.png](./img/gRm2W1HnH39pA6h9/1744942097160-3b3ace89-9297-4f90-8dfd-ee94e32bcf8c-926001.png)



# 缓存策略测试分析
## 1. 测试场景概述
### 1.1 热点数据访问测试 (testHotDataAccess)
#### 测试代码：
```cpp
void testHotDataAccess() {
    std::cout << "\n=== 测试场景1：热点数据访问测试 ===" << std::endl;
    
    const int CAPACITY = 20;         // 缓存容量
    const int OPERATIONS = 500000;   // 总操作次数
    const int HOT_KEYS = 20;         // 热点数据数量
    const int COLD_KEYS = 5000;      // 冷数据数量
    
    KamaCache::KLruCache<int, std::string> lru(CAPACITY);
    KamaCache::KLfuCache<int, std::string> lfu(CAPACITY);
    KamaCache::KArcCache<int, std::string> arc(CAPACITY);

    // 生成随机数种子，类似与rand()，但是更优
    std::random_device rd;
    std::mt19937 gen(rd());
    
    // 基类指针指向派生类对象（多态）
    std::array<KamaCache::KICachePolicy<int, std::string>*, 3> caches = {&lru, &lfu, &arc};
    std::vector<int> hits(3, 0); // 记录三种策略分别缓存命中次数
    std::vector<int> get_operations(3, 0); // 三种策略测试分别get访问缓存总次数
    std::vector<std::string> names = {"LRU", "LFU", "ARC"};

    // 为所有的缓存对象进行相同的操作序列测试
    for (int i = 0; i < caches.size(); ++i) {
        // 先预热缓存，插入一些数据
        for (int key = 0; key < HOT_KEYS; ++key) {
            std::string value = "value" + std::to_string(key);
            caches[i]->put(key, value);
        }
        
        // 交替进行put和get操作，模拟真实场景
        for (int op = 0; op < OPERATIONS; ++op) {
            // 大多数缓存系统中读操作比写操作频繁
            // 所以设置30%概率进行写操作
            bool isPut = (gen() % 100 < 30); 
            int key;
            
            // 70%概率访问热点数据，30%概率访问冷数据
            if (gen() % 100 < 70) {
                key = gen() % HOT_KEYS; // 热点数据
            } else {
                key = HOT_KEYS + (gen() % COLD_KEYS); // 冷数据
            }
            
            if (isPut) {
                // 执行put操作
                std::string value = "value" + std::to_string(key) + "_v" + std::to_string(op % 100);
                caches[i]->put(key, value);
            } else {
                // 执行get操作并记录命中情况
                std::string result;
                get_operations[i]++;
                if (caches[i]->get(key, result)) {
                    hits[i]++;
                }
            }
        }
    }

    // 打印测试结果
    printResults("热点数据访问测试", CAPACITY, get_operations, hits);
}
```

#### 测试代码解释
**测试特征：**

+ 缓存容量：20
+ 操作次数：500,000
+ get访问缓存 和 put添加缓存比例，为了模拟真实场景，测试做了以下安排：
    - 先进行预热，加载热点数据
    - 测试过程中get和put随机交叉进行，put发生的概率是30%，get发生的概率是70%（反应了大多数缓存系统中读操作通常比写操作更频繁的特性）。
    - 实时记录了命中次数和总读取次数。
+ 数据访问偏向性模拟（模拟现实应用中的“二八法则”- 少量数据被大量访问，大量数据被少量访问）：
    - 70% 访问热点数据（key范围：0-19）
    - 30% 访问冷数据（key范围：20-4999）

**测试目的：**

+ 验证缓存对频繁访问的少量数据的处理能力
+ 测试在大量冷数据干扰下的缓存性能

**有利策略：**

+ LFU：因为能准确跟踪访问频率，对热点数据有很好的保留能力
+ ARC：能够通过自适应机制在列表中保留频繁访问的数据





### 1.2 循环扫描测试 (testLoopPattern)
#### 测试代码：
```cpp
void testLoopPattern() {
    std::cout << "\n=== 测试场景2：循环扫描测试 ===" << std::endl;
    
    const int CAPACITY = 50;          // 缓存容量
    const int LOOP_SIZE = 500;        // 循环范围大小
    const int OPERATIONS = 200000;    // 总操作次数
    
    KamaCache::KLruCache<int, std::string> lru(CAPACITY);
    KamaCache::KLfuCache<int, std::string> lfu(CAPACITY);
    KamaCache::KArcCache<int, std::string> arc(CAPACITY);

    std::array<KamaCache::KICachePolicy<int, std::string>*, 3> caches = {&lru, &lfu, &arc};
    std::vector<int> hits(3, 0);
    std::vector<int> get_operations(3, 0);
    std::vector<std::string> names = {"LRU", "LFU", "ARC"};

    std::random_device rd;
    std::mt19937 gen(rd());

    // 为每种缓存算法运行相同的测试
    for (int i = 0; i < caches.size(); ++i) {
        
        // 先预热一部分数据（只加载20%的数据）
        for (int key = 0; key < LOOP_SIZE / 5; ++key) {
            std::string value = "loop" + std::to_string(key);
            caches[i]->put(key, value);
        }
        
        // 设置循环扫描的当前位置
        int current_pos = 0;
        
        // 交替进行读写操作，模拟真实场景
        for (int op = 0; op < OPERATIONS; ++op) {
            // 20%概率是写操作，80%概率是读操作
            bool isPut = (gen() % 100 < 20);
            int key;
            
            // 按照不同模式选择键
            if (op % 100 < 60) {  // 60%顺序扫描
                key = current_pos;
                current_pos = (current_pos + 1) % LOOP_SIZE;
            } else if (op % 100 < 90) {  // 30%随机跳跃
                key = gen() % LOOP_SIZE;
            } else {  // 10%访问范围外数据
                key = LOOP_SIZE + (gen() % LOOP_SIZE);
            }
            
            if (isPut) {
                // 执行put操作，更新数据
                std::string value = "loop" + std::to_string(key) + "_v" + std::to_string(op % 100);
                caches[i]->put(key, value);
            } else {
                // 执行get操作并记录命中情况
                std::string result;
                get_operations[i]++;
                if (caches[i]->get(key, result)) {
                    hits[i]++;
                }
            }
        }
    }

    printResults("循环扫描测试", CAPACITY, get_operations, hits);
}
```

#### 测试代码解释：
**测试特征：**

+ 缓存容量：30
+ 循环范围：500
+ 操作次数：80000
+ get访问缓存 和 put添加缓存比例，为了模拟真实场景，测试做了以下安排：
    - 只预热了20%的数据，而不是全部500个键值对。这更符合真实场景，缓存通常是逐渐填充的，而不是一次性完全填满。
    - 测试过程中get和put随机交叉进行，put发生的概率是20%，get发生的概率是80%（循环扫描场景读中，读操作更频繁）。
    - 实时记录了命中次数和总读取次数。
+ 访问模式：
    - 60% 顺序扫描（每次 key + 1 % 循环范围）
    - 30% 随机跳跃（循环范围内的随机数）
    - 10% 范围外访问（循环范围外的随机数）

**测试目的：**

+ 验证缓存在顺序访问模式下的表现
+ 测试缓存对周期性访问模式的适应能力
+ 评估缓存在数据局部性变化时的性能

**策略对比：**

+ LRU的弱点：在循环扫描模式下，LRU容易发生"缓存抖动"，因为最近使用的数据可能立即被新的扫描数据替换。
+ LFU的表现：循环扫描模式下，如果某些数据被重复扫描多次，LFU可能会表现更好。
+ ARC的优势：ARC通过同时考虑访问频率和时间，可能在这种混合访问模式下有更平衡的表现。

### 1.3 工作负载剧烈变化测试 (testWorkloadShift)
#### 测试代码：
```cpp
void testWorkloadShift() {
    std::cout << "\n=== 测试场景3：工作负载剧烈变化测试 ===" << std::endl;
    
    const int CAPACITY = 30;            // 缓存容量
    const int OPERATIONS = 80000;       // 总操作次数
    const int PHASE_LENGTH = OPERATIONS / 5;  // 每个阶段的长度
    
    KamaCache::KLruCache<int, std::string> lru(CAPACITY);
    KamaCache::KLfuCache<int, std::string> lfu(CAPACITY);
    KamaCache::KArcCache<int, std::string> arc(CAPACITY);

    std::random_device rd;
    std::mt19937 gen(rd());
    std::array<KamaCache::KICachePolicy<int, std::string>*, 3> caches = {&lru, &lfu, &arc};
    std::vector<int> hits(3, 0);
    std::vector<int> get_operations(3, 0);
    std::vector<std::string> names = {"LRU", "LFU", "ARC"};

    // 为每种缓存算法运行相同的测试
    for (int i = 0; i < caches.size(); ++i) {
        // 先预热缓存，只插入少量初始数据
        for (int key = 0; key < 30; ++key) {
            std::string value = "init" + std::to_string(key);
            caches[i]->put(key, value);
        }
        
        // 进行多阶段测试，每个阶段有不同的访问模式
        for (int op = 0; op < OPERATIONS; ++op) {
            // 确定当前阶段
            int phase = op / PHASE_LENGTH;
            
            // 每个阶段的读写比例不同 - 优化后的比例
            int putProbability;
            switch (phase) {
                case 0: putProbability = 15; break;  // 阶段1: 热点访问，15%写入更合理
                case 1: putProbability = 30; break;  // 阶段2: 大范围随机，降低写比例为30%
                case 2: putProbability = 10; break;  // 阶段3: 顺序扫描，10%写入保持不变
                case 3: putProbability = 25; break;  // 阶段4: 局部性随机，微调为25%
                case 4: putProbability = 20; break;  // 阶段5: 混合访问，调整为20%
                default: putProbability = 20;
            }
            
            // 确定是读还是写操作
            bool isPut = (gen() % 100 < putProbability);
            
            // 根据不同阶段选择不同的访问模式生成key - 优化后的访问范围
            int key;
            if (op < PHASE_LENGTH) {  // 阶段1: 热点访问 - 减少热点数量从10到5，使热点更集中
                key = gen() % 5;
            } else if (op < PHASE_LENGTH * 2) {  // 阶段2: 大范围随机 - 范围从1000减小到400，更适合20大小的缓存
                key = gen() % 400;
            } else if (op < PHASE_LENGTH * 3) {  // 阶段3: 顺序扫描 - 保持100个键
                key = (op - PHASE_LENGTH * 2) % 100;
            } else if (op < PHASE_LENGTH * 4) {  // 阶段4: 局部性随机 - 优化局部性区域大小
                // 产生5个局部区域，每个区域大小为15个键，与缓存大小20接近但略小
                int locality = (op / 800) % 5;  // 调整为5个局部区域
                key = locality * 15 + (gen() % 15);  // 每区域15个键
            } else {  // 阶段5: 混合访问 - 增加热点访问比例
                int r = gen() % 100;
                if (r < 40) {  // 40%概率访问热点（从30%增加）
                    key = gen() % 5;  // 5个热点键
                } else if (r < 70) {  // 30%概率访问中等范围
                    key = 5 + (gen() % 45);  // 缩小中等范围为50个键
                } else {  // 30%概率访问大范围（从40%减少）
                    key = 50 + (gen() % 350);  // 大范围也相应缩小
                }
            }
            
            if (isPut) {
                // 执行写操作
                std::string value = "value" + std::to_string(key) + "_p" + std::to_string(phase);
                caches[i]->put(key, value);
            } else {
                // 执行读操作并记录命中情况
                std::string result;
                get_operations[i]++;
                if (caches[i]->get(key, result)) {
                    hits[i]++;
                }
            }
        }
    }

    printResults("工作负载剧烈变化测试", CAPACITY, get_operations, hits);
}
```

#### **测试代码解释：**
**测试特征：**

+ 缓存容量：30
+ 操作次数：80,000
+ get访问缓存 和 put添加缓存比例，为了模拟真实场景，测试做了以下安排：
    - 读写交替进行，每个阶段的读写比例不同。
    - 阶段1: 热点访问，15%写入。
    - 阶段2: 大范围随机，写比例30%。
    - 阶段3: 顺序扫描，10%写入。
    - 阶段4: 局部性随机，微调为25%。
    - 阶段5: 混合访问，调整为20%。
+ 五个不同访问阶段（每个阶段操作80,000 / 5 次）：
    1. 热点访问（少量key密集访问）
    2. 大范围随机访问（400个key随机访问）
    3. 顺序扫描（100个key，按顺序递增访问）
    4. 局部性随机访问（分区域随机）
    5. 混合访问模式（40%概率访问热点数据，30%概率随机访问中等范围数据，30%概率访问大范围数据）

**测试目的：**

+ 评估缓存在工作负载突变时的适应能力
+ 测试不同缓存策略在复杂访问模式下的表现
+ 验证缓存算法的稳定性和自适应能力

**策略对比：**

+ LRU可能在工作负载变化时迅速调整，但缺乏长期记忆
+ LFU可能保持长期记忆，但调整较慢
+ ARC应该能在这两者间取得平衡

## 2. 测试设计特点
#### 2.1 数据操作分离
+ 将put和get操作分开执行
+ 避免了put后立即get导致的虚假高命中率

#### 2.2 动态数据范围
+ 通过动态改变数据访问范围
+ 模拟真实环境中数据分布的变化

#### 2.3 多样化访问模式
+ 结合顺序访问、随机访问和局部性访问
+ 更接近实际应用场景

## 3. 预期效果分析
#### 3.1 LRU 策略
+ 优势场景：
    - 具有时间局部性的访问模式
    - 工作集大小小于缓存容量的情况
+ 劣势场景：
    - 循环扫描大量数据
    - 频繁访问的数据集大于缓存容量

#### 3.2 LFU 策略
+ 优势场景：
    - 稳定的热点数据访问
    - 访问频率分布稳定的工作负载
+ 劣势场景：
    - 访问模式突变
    - 临时突发的高频访问

#### 3.3 ARC 策略
+ 优势场景：
    - 复杂的混合访问模式
    - 工作负载频繁变化
    - 同时存在时间和频率局部性
+ 劣势场景：
    - 极端单一的访问模式（纯随机或纯顺序）

## 4. 测试结果分析要点
+ 关注命中率的绝对值
+ 观察不同策略在场景切换时的适应速度
+ 比较策略间的性能差异
+ 验证各策略在其优势场景中的表现



### 


> 更新: 2025-04-18 11:15:00  
> 原文: <https://www.yuque.com/chengxuyuancarl/ctp2tl/rpwawcobio2tsm7e>